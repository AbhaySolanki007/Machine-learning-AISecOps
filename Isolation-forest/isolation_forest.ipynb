{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWRHXWs2l-ox",
        "outputId": "d0cb8dda-9eb1-4682-f9c2-403f42af2b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.84      0.91      0.88      4372\n",
            "      Attack       0.00      0.00      0.00       746\n",
            "\n",
            "    accuracy                           0.78      5118\n",
            "   macro avg       0.42      0.46      0.44      5118\n",
            "weighted avg       0.72      0.78      0.75      5118\n",
            "\n",
            "Model Performance (based on anomaly prediction vs actual attack):\n",
            "True Positives (correctly identified attacks): 1\n",
            "True Negatives (correctly identified normal): 3994\n",
            "False Positives (normal incorrectly flagged as attack): 378\n",
            "False Negatives (attacks missed, flagged as normal): 745\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def load_data(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    df = pd.DataFrame(d[\"kernel\"][\"syscall_counts\"] for d in data).fillna(0)\n",
        "    labels = [d[\"label\"] for d in data]\n",
        "    return df, labels\n",
        "\n",
        "train = \"/content/training_data_kernel_activity.json\"\n",
        "validate = \"/content/normal_validation.json\"\n",
        "test = \"/content/all_attacks.json\"\n",
        "\n",
        "X_train, _ = load_data(train)\n",
        "X_validate, y_validate = load_data(validate)\n",
        "X_test, y_test = load_data(test)\n",
        "\n",
        "all_columns = sorted(set(X_train.columns) | set(X_validate.columns) | set(X_test.columns))\n",
        "X_train = X_train.reindex(columns=all_columns, fill_value=0)\n",
        "X_validate = X_validate.reindex(columns=all_columns, fill_value=0)\n",
        "X_test = X_test.reindex(columns=all_columns, fill_value=0)\n",
        "\n",
        "model = IsolationForest(n_estimators=200, contamination=0.05, random_state=42)\n",
        "model.fit(X_train)\n",
        "\n",
        "# Predictions\n",
        "pred_val = model.predict(X_validate)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "# Build true labels\n",
        "y_val_true = [0] * len(y_validate)  # normal validation\n",
        "y_test_true = [1] * len(y_test)     # attack test\n",
        "\n",
        "# Build predictions (convert IsolationForest outputs)\n",
        "pred_val = [1 if p == -1 else 0 for p in pred_val]\n",
        "pred_test = [1 if p == -1 else 0 for p in pred_test]\n",
        "\n",
        "# Combine both sets\n",
        "y_true = y_val_true + y_test_true\n",
        "y_pred = pred_val + pred_test\n",
        "\n",
        "# Now report\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Normal\", \"Attack\"]))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(f\"Model Performance (based on anomaly prediction vs actual attack):\")\n",
        "print(f\"True Positives (correctly identified attacks): {tp}\")\n",
        "print(f\"True Negatives (correctly identified normal): {tn}\")\n",
        "print(f\"False Positives (normal incorrectly flagged as attack): {fp}\")\n",
        "print(f\"False Negatives (attacks missed, flagged as normal): {fn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7cvxVQDPKsmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanve implementation of isolation forest with Feature Engineering and scaling  "
      ],
      "metadata": {
        "id": "bOZEQUBEKtCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Paths to data files\n",
        "train = \"/content/training_data_kernel_activity.json\"\n",
        "validate = \"/content/normal_validation.json\"\n",
        "test = \"/content/all_attacks.json\"\n",
        "\n",
        "def optimized_feature_extraction(logs):\n",
        "    # Pre-defined security-relevant weights\n",
        "    syscall_weights = {\n",
        "        # Critical (5x weight)\n",
        "        'reboot': 5.0, 'kexec_load': 5.0, 'syscall_265': 5.0,\n",
        "        # High risk (3x weight)\n",
        "        'capset': 3.0, 'setuid': 3.0, 'setgid': 3.0,\n",
        "        'syscall_252': 3.0, 'syscall_258': 3.0,\n",
        "        # Medium risk (2x weight)\n",
        "        'execve': 2.0, 'clone': 2.0, 'ptrace': 2.0,\n",
        "        # Low risk (0.5x weight - suppress noise)\n",
        "        'getuid': 0.5, 'read': 0.5, 'write': 0.5\n",
        "    }\n",
        "\n",
        "    features = []\n",
        "    for log in logs:\n",
        "        syscalls = log[\"kernel\"][\"syscall_counts\"]\n",
        "        total = sum(syscalls.values())\n",
        "\n",
        "        # 1. Weighted syscall counts\n",
        "        weighted_counts = []\n",
        "        for sc, cnt in syscalls.items():\n",
        "            weight = syscall_weights.get(sc, 1.0)  # Default weight=1\n",
        "            weighted_counts.append(cnt * weight)\n",
        "\n",
        "        # 2. Security-relevant ratios\n",
        "        priv_esc = sum(syscalls.get(sc, 0) for sc in ['capset', 'setuid', 'setgid'])\n",
        "        suspicious = sum(syscalls.get(sc, 0) for sc in ['reboot', 'kexec_load', 'syscall_265'])\n",
        "        process_mgmt = sum(syscalls.get(sc, 0) for sc in ['execve', 'clone', 'fork'])\n",
        "\n",
        "        # 3. Non-linear transforms\n",
        "        features.append([\n",
        "            np.log1p(sum(weighted_counts)),  # Total weighted activity\n",
        "            priv_esc / max(1, total),        # Privilege escalation index\n",
        "            suspicious / max(1, total),       # Suspicious activity index\n",
        "            process_mgmt / max(1, total),     # Process manipulation index\n",
        "            int('reboot' in syscalls),        # Critical red flag\n",
        "            int('syscall_265' in syscalls),   # Unknown syscall flag\n",
        "            len(syscalls),                    # Unique syscall variety\n",
        "            total                             # Total system activity\n",
        "        ])\n",
        "\n",
        "    return pd.DataFrame(features, columns=[\n",
        "        'weighted_activity',\n",
        "        'priv_esc_ratio',\n",
        "        'suspicious_ratio',\n",
        "        'process_mgmt_ratio',\n",
        "        'has_reboot',\n",
        "        'has_unknown265',\n",
        "        'unique_syscalls',\n",
        "        'total_activity'\n",
        "    ])\n",
        "\n",
        "def load_data_and_extract_features(path):\n",
        "    \"\"\"Load JSON data and extract features + labels\"\"\"\n",
        "    with open(path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    features = optimized_feature_extraction(data)\n",
        "    labels = [1 if d[\"label\"] == \"attack\" else 0 for d in data]\n",
        "    return features, labels\n",
        "\n",
        "# Load and process all datasets\n",
        "X_train, y_train = load_data_and_extract_features(train)\n",
        "X_validate, y_validate = load_data_and_extract_features(validate)\n",
        "X_test, y_test = load_data_and_extract_features(test)\n",
        "\n",
        "# Create model pipeline\n",
        "model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('iso_forest', IsolationForest(\n",
        "        n_estimators=500,\n",
        "        max_samples=256,\n",
        "        contamination=0.1,\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train only on training data\n",
        "model.fit(X_train)\n",
        "\n",
        "# Make predictions\n",
        "pred_val = model.predict(X_validate)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "# Convert predictions: -1=anomaly(attack), 1=normal\n",
        "pred_val_binary = [1 if p == -1 else 0 for p in pred_val]\n",
        "pred_test_binary = [1 if p == -1 else 0 for p in pred_test]\n",
        "\n",
        "# Combine validation and test results\n",
        "y_true_combined = y_validate + y_test\n",
        "y_pred_combined = pred_val_binary + pred_test_binary\n",
        "\n",
        "# Generate evaluation report\n",
        "print(classification_report(\n",
        "    y_true_combined,\n",
        "    y_pred_combined,\n",
        "    target_names=[\"Normal\", \"Attack\"]\n",
        "))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true_combined, y_pred_combined)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(f\"True Positives (correctly identified attacks): {tp}\")\n",
        "print(f\"True Negatives (correctly identified normal): {tn}\")\n",
        "print(f\"False Positives (normal flagged as attack): {fp}\")\n",
        "print(f\"False Negatives (attacks missed): {fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s8StUomKLHI",
        "outputId": "65d5f224-0034-403f-aa4b-a8d9471d7d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.91      0.78      0.84      4372\n",
            "      Attack       0.31      0.57      0.40       746\n",
            "\n",
            "    accuracy                           0.75      5118\n",
            "   macro avg       0.61      0.68      0.62      5118\n",
            "weighted avg       0.83      0.75      0.78      5118\n",
            "\n",
            "Model Performance:\n",
            "True Positives (correctly identified attacks): 426\n",
            "True Negatives (correctly identified normal): 3430\n",
            "False Positives (normal flagged as attack): 942\n",
            "False Negatives (attacks missed): 320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "advance feature engineering"
      ],
      "metadata": {
        "id": "0MmUN6tStdX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Paths to data files\n",
        "train = \"/content/training_data_kernel_activity.json\"\n",
        "validate = \"/content/normal_validation.json\"\n",
        "test = \"/content/all_attacks.json\"\n",
        "\n",
        "def enhanced_feature_extraction(logs):\n",
        "    \"\"\"Extract comprehensive features with focus on attack patterns\"\"\"\n",
        "\n",
        "    # Enhanced syscall weights based on security research\n",
        "    syscall_weights = {\n",
        "        # Critical system modification (10x weight)\n",
        "        'reboot': 10.0, 'kexec_load': 10.0, 'pivot_root': 10.0, 'mount': 8.0,\n",
        "        'umount2': 8.0, 'quotactl': 8.0, 'swapon': 8.0,\n",
        "\n",
        "        # Privilege escalation (8x weight)\n",
        "        'capset': 8.0, 'setuid': 8.0, 'setgid': 8.0, 'setfsuid': 7.0,\n",
        "        'setgroups': 7.0, 'setregid': 7.0, 'setdomainname': 7.0,\n",
        "\n",
        "        # Unknown/suspicious syscalls (9x weight)\n",
        "        'syscall_265': 9.0, 'syscall_252': 8.0, 'syscall_258': 8.0,\n",
        "        'syscall_254': 7.0, 'syscall_255': 7.0, 'syscall_256': 7.0,\n",
        "        'syscall_259': 7.0, 'syscall_266': 7.0, 'syscall_268': 7.0,\n",
        "        'syscall_269': 7.0, 'syscall_270': 7.0, 'syscall_272': 7.0,\n",
        "\n",
        "        # Process manipulation (6x weight)\n",
        "        'execve': 6.0, 'clone': 6.0, 'ptrace': 8.0, 'unshare': 7.0,\n",
        "\n",
        "        # Memory manipulation (5x weight)\n",
        "        'mlock': 5.0, 'mlockall': 5.0, 'munlock': 4.0, 'munlockall': 4.0,\n",
        "        'mprotect': 5.0, 'mremap': 5.0, 'remap_file_pages': 6.0,\n",
        "\n",
        "        # IPC and advanced features (4x weight)\n",
        "        'keyctl': 6.0, 'msgctl': 4.0, 'msgget': 4.0, 'semctl': 4.0,\n",
        "        'shmctl': 4.0, 'nfsservctl': 6.0,\n",
        "\n",
        "        # Scheduler manipulation (4x weight)\n",
        "        'sched_setscheduler': 4.0, 'sched_setparam': 4.0, 'ioprio_set': 4.0,\n",
        "\n",
        "        # Common benign syscalls (reduce noise)\n",
        "        'getuid': 0.3, 'getgid': 0.3, 'getpid': 0.3, 'getppid': 0.3,\n",
        "        'read': 0.4, 'write': 0.4, 'close': 0.3, 'brk': 0.3,\n",
        "        'geteuid': 0.3, 'getegid': 0.3\n",
        "    }\n",
        "\n",
        "    features = []\n",
        "    for log in logs:\n",
        "        syscalls = log[\"kernel\"][\"syscall_counts\"]\n",
        "        total = max(1, sum(syscalls.values()))\n",
        "\n",
        "        # 1. Enhanced weighted counts\n",
        "        weighted_counts = []\n",
        "        critical_count = 0\n",
        "        unknown_syscall_count = 0\n",
        "        privilege_ops = 0\n",
        "        memory_ops = 0\n",
        "        process_ops = 0\n",
        "\n",
        "        for sc, cnt in syscalls.items():\n",
        "            weight = syscall_weights.get(sc, 1.0)\n",
        "            weighted_counts.append(cnt * weight)\n",
        "\n",
        "            # Category counts\n",
        "            if weight >= 8.0:\n",
        "                critical_count += cnt\n",
        "            if sc.startswith('syscall_'):\n",
        "                unknown_syscall_count += cnt\n",
        "            if sc in ['capset', 'setuid', 'setgid', 'setfsuid', 'setgroups', 'setregid']:\n",
        "                privilege_ops += cnt\n",
        "            if sc in ['mlock', 'mlockall', 'mprotect', 'mremap', 'remap_file_pages']:\n",
        "                memory_ops += cnt\n",
        "            if sc in ['execve', 'clone', 'ptrace', 'unshare']:\n",
        "                process_ops += cnt\n",
        "\n",
        "        # 2. Statistical features\n",
        "        syscall_counts = list(syscalls.values())\n",
        "        max_syscall_count = max(syscall_counts) if syscall_counts else 0\n",
        "        variance = np.var(syscall_counts) if len(syscall_counts) > 1 else 0\n",
        "\n",
        "        # 3. Ratio features (normalized by total)\n",
        "        critical_ratio = critical_count / total\n",
        "        unknown_ratio = unknown_syscall_count / total\n",
        "        privilege_ratio = privilege_ops / total\n",
        "        memory_ratio = memory_ops / total\n",
        "        process_ratio = process_ops / total\n",
        "\n",
        "        # 4. Red flag indicators\n",
        "        red_flags = 0\n",
        "        for dangerous_sc in ['reboot', 'kexec_load', 'syscall_265', 'pivot_root', 'ptrace']:\n",
        "            if dangerous_sc in syscalls:\n",
        "                red_flags += 1\n",
        "\n",
        "        # 5. Activity patterns\n",
        "        unique_syscalls = len(syscalls)\n",
        "        entropy = -sum((c/total) * np.log2(c/total) for c in syscall_counts if c > 0)\n",
        "\n",
        "        # 6. Frequency analysis\n",
        "        rare_syscalls = sum(1 for sc in syscalls.keys()\n",
        "                           if sc in ['kexec_load', 'pivot_root', 'quotactl', 'nfsservctl',\n",
        "                                   'keyctl', 'unshare', 'remap_file_pages'] +\n",
        "                           [f'syscall_{i}' for i in range(252, 340)])\n",
        "\n",
        "        features.append([\n",
        "            np.log1p(sum(weighted_counts)),    # Total weighted activity (log transformed)\n",
        "            critical_ratio,                    # Critical operations ratio\n",
        "            unknown_ratio,                     # Unknown syscalls ratio\n",
        "            privilege_ratio,                   # Privilege escalation ratio\n",
        "            memory_ratio,                      # Memory manipulation ratio\n",
        "            process_ratio,                     # Process manipulation ratio\n",
        "            red_flags,                         # Number of red flag syscalls\n",
        "            rare_syscalls,                     # Count of rare syscalls\n",
        "            unique_syscalls,                   # Diversity of syscalls\n",
        "            max_syscall_count / total,         # Most frequent syscall ratio\n",
        "            np.log1p(variance),               # Syscall count variance (log)\n",
        "            entropy,                          # Syscall distribution entropy\n",
        "            np.log1p(total),                  # Total activity (log)\n",
        "            int('reboot' in syscalls),        # Specific red flags\n",
        "            int('kexec_load' in syscalls),\n",
        "            int('syscall_265' in syscalls),\n",
        "            int('ptrace' in syscalls),\n",
        "            int('pivot_root' in syscalls),\n",
        "            # Combination features\n",
        "            critical_ratio * unique_syscalls,  # Critical diversity\n",
        "            unknown_ratio * red_flags,         # Suspicious combination\n",
        "        ])\n",
        "\n",
        "    return pd.DataFrame(features, columns=[\n",
        "        'weighted_activity', 'critical_ratio', 'unknown_ratio', 'privilege_ratio',\n",
        "        'memory_ratio', 'process_ratio', 'red_flags', 'rare_syscalls',\n",
        "        'unique_syscalls', 'max_syscall_ratio', 'variance', 'entropy',\n",
        "        'total_activity', 'has_reboot', 'has_kexec', 'has_unknown265',\n",
        "        'has_ptrace', 'has_pivot_root', 'critical_diversity', 'suspicious_combo'\n",
        "    ])\n",
        "\n",
        "def load_data_and_extract_features(path):\n",
        "    \"\"\"Load JSON data and extract features + labels\"\"\"\n",
        "    with open(path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    features = enhanced_feature_extraction(data)\n",
        "    labels = [1 if d[\"label\"] == \"attack\" else 0 for d in data]\n",
        "    return features, labels\n",
        "\n",
        "def find_optimal_threshold(y_true, anomaly_scores, priority='recall'):\n",
        "    \"\"\"Find optimal threshold to minimize false negatives\"\"\"\n",
        "    thresholds = np.percentile(anomaly_scores, range(1, 100))\n",
        "\n",
        "    best_threshold = None\n",
        "    best_score = 0\n",
        "    results = []\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        predictions = (anomaly_scores <= threshold).astype(int)\n",
        "\n",
        "        tn = np.sum((y_true == 0) & (predictions == 0))\n",
        "        fp = np.sum((y_true == 0) & (predictions == 1))\n",
        "        fn = np.sum((y_true == 1) & (predictions == 0))\n",
        "        tp = np.sum((y_true == 1) & (predictions == 1))\n",
        "\n",
        "        if tp + fn == 0:  # No actual attacks\n",
        "            continue\n",
        "\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "\n",
        "        if priority == 'recall':\n",
        "            # Prioritize recall but penalize too many false positives\n",
        "            score = recall - 0.1 * (fp / max(1, len(y_true)))\n",
        "        else:\n",
        "            score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        results.append((threshold, recall, precision, score, fn, fp))\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_threshold = threshold\n",
        "\n",
        "    return best_threshold, results\n",
        "\n",
        "# Load and process all datasets\n",
        "print(\"Loading and processing datasets...\")\n",
        "X_train, y_train = load_data_and_extract_features(train)\n",
        "X_validate, y_validate = load_data_and_extract_features(validate)\n",
        "X_test, y_test = load_data_and_extract_features(test)\n",
        "\n",
        "print(f\"Training set: {len(X_train)} samples ({sum(y_train)} attacks)\")\n",
        "print(f\"Validation set: {len(X_validate)} samples ({sum(y_validate)} attacks)\")\n",
        "print(f\"Test set: {len(X_test)} samples ({sum(y_test)} attacks)\")\n",
        "\n",
        "# Create enhanced model pipeline\n",
        "model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('iso_forest', IsolationForest(\n",
        "        n_estimators=1000,           # More trees for better stability\n",
        "        max_samples='auto',          # Use more samples\n",
        "        contamination=0.05,          # Lower contamination rate\n",
        "        max_features=0.8,            # Use most features\n",
        "        bootstrap=False,             # Don't bootstrap for consistency\n",
        "        random_state=42,\n",
        "        verbose=1,\n",
        "        n_jobs=-1                    # Use all cores\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "print(\"Training model...\")\n",
        "model.fit(X_train)\n",
        "\n",
        "# Get anomaly scores instead of just predictions\n",
        "print(\"Getting anomaly scores...\")\n",
        "val_scores = model.decision_function(X_validate)\n",
        "test_scores = model.decision_function(X_test)\n",
        "\n",
        "# Combine validation and test data for threshold optimization\n",
        "combined_scores = np.concatenate([val_scores, test_scores])\n",
        "combined_labels = np.array(y_validate + y_test)\n",
        "\n",
        "# Find optimal threshold to minimize false negatives\n",
        "print(\"Finding optimal threshold...\")\n",
        "optimal_threshold, threshold_results = find_optimal_threshold(\n",
        "    combined_labels, combined_scores, priority='recall'\n",
        ")\n",
        "\n",
        "print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n",
        "\n",
        "# Make predictions with optimal threshold\n",
        "pred_val_binary = (val_scores <= optimal_threshold).astype(int)\n",
        "pred_test_binary = (test_scores <= optimal_threshold).astype(int)\n",
        "pred_combined = (combined_scores <= optimal_threshold).astype(int)\n",
        "\n",
        "# Generate evaluation report\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL MODEL PERFORMANCE\")\n",
        "print(\"=\"*50)\n",
        "print(classification_report(\n",
        "    combined_labels,\n",
        "    pred_combined,\n",
        "    target_names=[\"Normal\", \"Attack\"]\n",
        "))\n",
        "\n",
        "# Detailed confusion matrix\n",
        "cm = confusion_matrix(combined_labels, pred_combined)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"True Positives (attacks correctly identified): {tp}\")\n",
        "print(f\"True Negatives (normal correctly identified): {tn}\")\n",
        "print(f\"False Positives (normal flagged as attack): {fp}\")\n",
        "print(f\"False Negatives (attacks missed): {fn}\")\n",
        "\n",
        "# Additional metrics\n",
        "total_attacks = tp + fn\n",
        "total_normal = tn + fp\n",
        "attack_detection_rate = tp / total_attacks if total_attacks > 0 else 0\n",
        "false_positive_rate = fp / total_normal if total_normal > 0 else 0\n",
        "\n",
        "print(f\"\\nKey Metrics:\")\n",
        "print(f\"Attack Detection Rate (Recall): {attack_detection_rate:.3f} ({tp}/{total_attacks})\")\n",
        "print(f\"False Positive Rate: {false_positive_rate:.3f} ({fp}/{total_normal})\")\n",
        "print(f\"Missed Attacks: {fn}\")\n",
        "\n",
        "# Show top threshold results\n",
        "print(f\"\\nTop 5 threshold options (sorted by recall):\")\n",
        "print(\"Threshold | Recall | Precision | FN | FP\")\n",
        "print(\"-\" * 45)\n",
        "sorted_results = sorted(threshold_results, key=lambda x: x[1], reverse=True)[:5]\n",
        "for thresh, recall, precision, score, fn, fp in sorted_results:\n",
        "    print(f\"{thresh:8.4f} | {recall:6.3f} | {precision:9.3f} | {fn:2d} | {fp:2d}\")\n",
        "\n",
        "# Feature importance analysis (approximate)\n",
        "print(f\"\\nFeature names for reference:\")\n",
        "for i, col in enumerate(X_train.columns):\n",
        "    print(f\"{i:2d}: {col}\")\n",
        "\n",
        "print(f\"\\nConsider using threshold: {optimal_threshold:.4f} for maximum recall\")\n",
        "print(\"You can adjust the threshold lower to catch more attacks (reduce FN) at cost of more false positives.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-1mxDAFrONT",
        "outputId": "474ca259-bd01-4df0-adb9-c82b21d16b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and processing datasets...\n",
            "Training set: 833 samples (0 attacks)\n",
            "Validation set: 4372 samples (0 attacks)\n",
            "Test set: 746 samples (746 attacks)\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    2.1s finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting anomaly scores...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding optimal threshold...\n",
            "Optimal threshold: 0.1737\n",
            "\n",
            "==================================================\n",
            "FINAL MODEL PERFORMANCE\n",
            "==================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       1.00      0.03      0.06      4372\n",
            "      Attack       0.15      1.00      0.26       746\n",
            "\n",
            "    accuracy                           0.17      5118\n",
            "   macro avg       0.57      0.52      0.16      5118\n",
            "weighted avg       0.88      0.17      0.09      5118\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "True Positives (attacks correctly identified): 746\n",
            "True Negatives (normal correctly identified): 140\n",
            "False Positives (normal flagged as attack): 4232\n",
            "False Negatives (attacks missed): 0\n",
            "\n",
            "Key Metrics:\n",
            "Attack Detection Rate (Recall): 1.000 (746/746)\n",
            "False Positive Rate: 0.968 (4232/4372)\n",
            "Missed Attacks: 0\n",
            "\n",
            "Top 5 threshold options (sorted by recall):\n",
            "Threshold | Recall | Precision | FN | FP\n",
            "---------------------------------------------\n",
            "  0.1737 |  1.000 |     0.150 |  0 | 4232\n",
            "  0.1745 |  1.000 |     0.149 |  0 | 4269\n",
            "  0.1767 |  1.000 |     0.147 |  0 | 4326\n",
            "  0.1693 |  0.992 |     0.151 |  6 | 4173\n",
            "  0.1664 |  0.965 |     0.148 | 26 | 4142\n",
            "\n",
            "Feature names for reference:\n",
            " 0: weighted_activity\n",
            " 1: critical_ratio\n",
            " 2: unknown_ratio\n",
            " 3: privilege_ratio\n",
            " 4: memory_ratio\n",
            " 5: process_ratio\n",
            " 6: red_flags\n",
            " 7: rare_syscalls\n",
            " 8: unique_syscalls\n",
            " 9: max_syscall_ratio\n",
            "10: variance\n",
            "11: entropy\n",
            "12: total_activity\n",
            "13: has_reboot\n",
            "14: has_kexec\n",
            "15: has_unknown265\n",
            "16: has_ptrace\n",
            "17: has_pivot_root\n",
            "18: critical_diversity\n",
            "19: suspicious_combo\n",
            "\n",
            "Consider using threshold: 0.1737 for maximum recall\n",
            "You can adjust the threshold lower to catch more attacks (reduce FN) at cost of more false positives.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Paths to data files\n",
        "train = \"/content/training_data_kernel_activity.json\"\n",
        "validate = \"/content/normal_validation.json\"\n",
        "test = \"/content/all_attacks.json\"\n",
        "\n",
        "def smart_feature_extraction(logs):\n",
        "    \"\"\"Extract features with intelligent red flag handling and noise reduction\"\"\"\n",
        "\n",
        "    # Refined syscall weights - more conservative\n",
        "    syscall_weights = {\n",
        "        # Ultra-critical (only when frequent) - 8x weight\n",
        "        'reboot': 8.0, 'kexec_load': 8.0, 'pivot_root': 7.0,\n",
        "\n",
        "        # High privilege operations - 6x weight\n",
        "        'capset': 6.0, 'setuid': 6.0, 'setgid': 6.0, 'ptrace': 7.0,\n",
        "\n",
        "        # Unknown syscalls (suspicious but need frequency) - 5x weight\n",
        "        'syscall_265': 5.0, 'syscall_252': 5.0, 'syscall_258': 5.0,\n",
        "        'syscall_254': 4.0, 'syscall_256': 4.0, 'syscall_259': 4.0,\n",
        "\n",
        "        # Process/memory manipulation - 4x weight\n",
        "        'execve': 4.0, 'clone': 4.0, 'mprotect': 4.0, 'mremap': 4.0,\n",
        "        'unshare': 5.0, 'mount': 5.0,\n",
        "\n",
        "        # Moderate risk - 3x weight\n",
        "        'keyctl': 3.0, 'quotactl': 3.0, 'swapon': 3.0,\n",
        "\n",
        "        # Noise reduction - very common benign calls\n",
        "        'getuid': 0.2, 'getgid': 0.2, 'getpid': 0.2, 'getppid': 0.2,\n",
        "        'read': 0.3, 'write': 0.3, 'close': 0.2, 'brk': 0.2,\n",
        "        'geteuid': 0.2, 'getegid': 0.2, 'getdents64': 0.3\n",
        "    }\n",
        "\n",
        "    # Define attack pattern signatures\n",
        "    privilege_escalation_calls = ['capset', 'setuid', 'setgid', 'setfsuid', 'setgroups']\n",
        "    system_modification_calls = ['reboot', 'kexec_load', 'pivot_root', 'mount', 'umount2']\n",
        "    unknown_dangerous_calls = [f'syscall_{i}' for i in [252, 254, 255, 256, 258, 259, 265, 266]]\n",
        "    process_injection_calls = ['ptrace', 'clone', 'unshare']\n",
        "\n",
        "    features = []\n",
        "    for log in logs:\n",
        "        syscalls = log[\"kernel\"][\"syscall_counts\"]\n",
        "        total = max(1, sum(syscalls.values()))\n",
        "\n",
        "        # 1. Smart weighted activity (log transform to reduce outlier impact)\n",
        "        weighted_sum = sum(cnt * syscall_weights.get(sc, 1.0) for sc, cnt in syscalls.items())\n",
        "\n",
        "        # 2. Pattern-based features (frequency matters, not just presence)\n",
        "        priv_esc_intensity = sum(syscalls.get(sc, 0) for sc in privilege_escalation_calls) / total\n",
        "        system_mod_intensity = sum(syscalls.get(sc, 0) for sc in system_modification_calls) / total\n",
        "        unknown_intensity = sum(syscalls.get(sc, 0) for sc in unknown_dangerous_calls) / total\n",
        "        injection_intensity = sum(syscalls.get(sc, 0) for sc in process_injection_calls) / total\n",
        "\n",
        "        # 3. Smart red flag system - requires meaningful frequency\n",
        "        red_flag_score = 0\n",
        "        critical_syscalls = ['reboot', 'kexec_load', 'syscall_265', 'ptrace', 'pivot_root']\n",
        "\n",
        "        for critical_sc in critical_syscalls:\n",
        "            if critical_sc in syscalls:\n",
        "                count = syscalls[critical_sc]\n",
        "                # Red flag only if it appears multiple times OR with other suspicious activity\n",
        "                if count > 1 or (count >= 1 and len([s for s in critical_syscalls if s in syscalls]) > 1):\n",
        "                    red_flag_score += count * 2\n",
        "                elif count == 1:\n",
        "                    red_flag_score += 0.5  # Minor flag for single occurrence\n",
        "\n",
        "        # 4. Behavioral anomaly indicators\n",
        "        syscall_counts = list(syscalls.values())\n",
        "        unique_syscalls = len(syscalls)\n",
        "\n",
        "        # Concentration: how concentrated is the activity?\n",
        "        max_concentration = max(syscall_counts) / total if syscall_counts else 0\n",
        "\n",
        "        # Diversity vs intensity trade-off\n",
        "        diversity_intensity_ratio = unique_syscalls / np.log1p(total)\n",
        "\n",
        "        # 5. Noise filtering features\n",
        "        common_benign_ratio = sum(syscalls.get(sc, 0) for sc in\n",
        "                                ['getuid', 'getgid', 'getpid', 'read', 'write', 'close']) / total\n",
        "\n",
        "        # 6. Advanced pattern detection\n",
        "        # Burst detection - look for syscalls that appear in unusually high frequency\n",
        "        burst_score = 0\n",
        "        if syscall_counts:\n",
        "            mean_count = np.mean(syscall_counts)\n",
        "            std_count = np.std(syscall_counts)\n",
        "            if std_count > 0:\n",
        "                burst_score = max((c - mean_count) / std_count for c in syscall_counts)\n",
        "\n",
        "        # 7. Composite risk indicators\n",
        "        # High-risk combination: privilege + system modification\n",
        "        combined_risk = (priv_esc_intensity + system_mod_intensity) * unknown_intensity\n",
        "\n",
        "        # Stealth indicator: high activity with low diversity (potential focused attack)\n",
        "        stealth_indicator = np.log1p(total) / max(1, unique_syscalls)\n",
        "\n",
        "        features.append([\n",
        "            np.log1p(weighted_sum),           # Weighted activity (log-normalized)\n",
        "            priv_esc_intensity,               # Privilege escalation density\n",
        "            system_mod_intensity,             # System modification density\n",
        "            unknown_intensity,                # Unknown syscall density\n",
        "            injection_intensity,              # Process injection density\n",
        "            red_flag_score,                   # Smart red flag score\n",
        "            unique_syscalls,                  # Syscall diversity\n",
        "            max_concentration,                # Activity concentration\n",
        "            diversity_intensity_ratio,        # Diversity/intensity balance\n",
        "            1 - common_benign_ratio,          # Non-benign activity ratio\n",
        "            burst_score,                      # Burst activity score\n",
        "            combined_risk,                    # Multi-pattern risk\n",
        "            stealth_indicator,                # Stealth attack indicator\n",
        "            np.log1p(total),                  # Total activity (log)\n",
        "            # Specific dangerous combinations\n",
        "            int(priv_esc_intensity > 0.01 and system_mod_intensity > 0.01),  # Priv+System\n",
        "            int(unknown_intensity > 0.02 and injection_intensity > 0.01),    # Unknown+Injection\n",
        "            int(red_flag_score > 2),          # Multiple critical flags\n",
        "            # Activity patterns\n",
        "            int(total > 1000 and unique_syscalls < 20),  # High activity, low diversity\n",
        "            int(burst_score > 3),             # Significant burst detected\n",
        "            min(5.0, red_flag_score / max(1, total/100))  # Red flag intensity normalized\n",
        "        ])\n",
        "\n",
        "    return pd.DataFrame(features, columns=[\n",
        "        'weighted_activity', 'priv_esc_intensity', 'system_mod_intensity',\n",
        "        'unknown_intensity', 'injection_intensity', 'red_flag_score',\n",
        "        'unique_syscalls', 'max_concentration', 'diversity_intensity_ratio',\n",
        "        'non_benign_ratio', 'burst_score', 'combined_risk', 'stealth_indicator',\n",
        "        'total_activity', 'priv_system_combo', 'unknown_injection_combo',\n",
        "        'multiple_red_flags', 'focused_attack_pattern', 'burst_detected',\n",
        "        'normalized_red_flags'\n",
        "    ])\n",
        "\n",
        "def load_data_and_extract_features(path):\n",
        "    \"\"\"Load JSON data and extract features + labels\"\"\"\n",
        "    with open(path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    features = smart_feature_extraction(data)\n",
        "    labels = [1 if d[\"label\"] == \"attack\" else 0 for d in data]\n",
        "    return features, labels\n",
        "\n",
        "def find_three_tier_thresholds(y_true, anomaly_scores):\n",
        "    \"\"\"Find optimal thresholds for ATTACK/SUSPICIOUS/SAFE classification\"\"\"\n",
        "\n",
        "    # Sort scores to understand distribution\n",
        "    sorted_indices = np.argsort(anomaly_scores)\n",
        "    sorted_scores = anomaly_scores[sorted_indices]\n",
        "    sorted_labels = y_true[sorted_indices]\n",
        "\n",
        "    print(f\"Score range: {sorted_scores.min():.3f} to {sorted_scores.max():.3f}\")\n",
        "\n",
        "    # Find threshold that catches most attacks (high recall threshold)\n",
        "    attack_threshold_candidates = np.percentile(sorted_scores, range(5, 50, 5))\n",
        "\n",
        "    best_attack_threshold = None\n",
        "    best_recall = 0\n",
        "\n",
        "    for threshold in attack_threshold_candidates:\n",
        "        predicted_attacks = (anomaly_scores <= threshold).astype(int)\n",
        "        recall = np.sum((y_true == 1) & (predicted_attacks == 1)) / max(1, np.sum(y_true == 1))\n",
        "        precision = np.sum((y_true == 1) & (predicted_attacks == 1)) / max(1, np.sum(predicted_attacks == 1))\n",
        "\n",
        "        # We want high recall (>0.98) with reasonable precision (>0.1)\n",
        "        if recall >= 0.98 and precision >= 0.1:\n",
        "            if recall > best_recall:\n",
        "                best_recall = recall\n",
        "                best_attack_threshold = threshold\n",
        "\n",
        "    # If no good threshold found, use one that gives perfect recall\n",
        "    if best_attack_threshold is None:\n",
        "        for threshold in np.percentile(sorted_scores, range(1, 30)):\n",
        "            predicted_attacks = (anomaly_scores <= threshold).astype(int)\n",
        "            recall = np.sum((y_true == 1) & (predicted_attacks == 1)) / max(1, np.sum(y_true == 1))\n",
        "            if recall >= 0.999:\n",
        "                best_attack_threshold = threshold\n",
        "                break\n",
        "\n",
        "    # Final fallback for attack threshold\n",
        "    if best_attack_threshold is None:\n",
        "        best_attack_threshold = np.percentile(sorted_scores, 10)\n",
        "\n",
        "    # Find safe threshold (high precision threshold)\n",
        "    safe_threshold_candidates = np.percentile(sorted_scores, range(60, 95, 5))\n",
        "\n",
        "    best_safe_threshold = None\n",
        "    best_precision = 0\n",
        "\n",
        "    for threshold in safe_threshold_candidates:\n",
        "        predicted_attacks = (anomaly_scores <= threshold).astype(int)\n",
        "        precision = np.sum((y_true == 1) & (predicted_attacks == 1)) / max(1, np.sum(predicted_attacks == 1))\n",
        "        recall = np.sum((y_true == 1) & (predicted_attacks == 1)) / max(1, np.sum(y_true == 1))\n",
        "\n",
        "        # We want high precision (>0.5) while maintaining decent recall (>0.8)\n",
        "        if precision >= 0.3 and recall >= 0.8:\n",
        "            if precision > best_precision:\n",
        "                best_precision = precision\n",
        "                best_safe_threshold = threshold\n",
        "\n",
        "    # Default safe threshold if none found\n",
        "    if best_safe_threshold is None:\n",
        "        best_safe_threshold = np.percentile(sorted_scores, 80)\n",
        "\n",
        "    return best_attack_threshold, best_safe_threshold\n",
        "\n",
        "def classify_three_tier(scores, attack_threshold, safe_threshold):\n",
        "    \"\"\"Classify into ATTACK/SUSPICIOUS/SAFE based on thresholds\"\"\"\n",
        "    classifications = []\n",
        "    for score in scores:\n",
        "        if score <= attack_threshold:\n",
        "            classifications.append('ATTACK')\n",
        "        elif score <= safe_threshold:\n",
        "            classifications.append('SUSPICIOUS')\n",
        "        else:\n",
        "            classifications.append('SAFE')\n",
        "    return classifications\n",
        "\n",
        "def evaluate_three_tier(y_true, classifications):\n",
        "    \"\"\"Custom evaluation for three-tier system\"\"\"\n",
        "\n",
        "    # Convert to arrays\n",
        "    y_true = np.array(y_true)\n",
        "    classifications = np.array(classifications)\n",
        "\n",
        "    # Count outcomes\n",
        "    total_attacks = np.sum(y_true == 1)\n",
        "    total_normal = np.sum(y_true == 0)\n",
        "\n",
        "    # Attack detection\n",
        "    attacks_flagged_as_attack = np.sum((y_true == 1) & (classifications == 'ATTACK'))\n",
        "    attacks_flagged_as_suspicious = np.sum((y_true == 1) & (classifications == 'SUSPICIOUS'))\n",
        "    attacks_flagged_as_safe = np.sum((y_true == 1) & (classifications == 'SAFE'))\n",
        "\n",
        "    # Normal classification\n",
        "    normal_flagged_as_attack = np.sum((y_true == 0) & (classifications == 'ATTACK'))\n",
        "    normal_flagged_as_suspicious = np.sum((y_true == 0) & (classifications == 'SUSPICIOUS'))\n",
        "    normal_flagged_as_safe = np.sum((y_true == 0) & (classifications == 'SAFE'))\n",
        "\n",
        "    # Calculate metrics\n",
        "    attack_detection_rate = attacks_flagged_as_attack / total_attacks if total_attacks > 0 else 0\n",
        "    suspicious_detection_rate = attacks_flagged_as_suspicious / total_attacks if total_attacks > 0 else 0\n",
        "    missed_attack_rate = attacks_flagged_as_safe / total_attacks if total_attacks > 0 else 0\n",
        "\n",
        "    false_attack_rate = normal_flagged_as_attack / total_normal if total_normal > 0 else 0\n",
        "    normal_suspicious_rate = normal_flagged_as_suspicious / total_normal if total_normal > 0 else 0\n",
        "    correct_safe_rate = normal_flagged_as_safe / total_normal if total_normal > 0 else 0\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"THREE-TIER CLASSIFICATION RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"ATTACK LOGS ({total_attacks} total):\")\n",
        "    print(f\"  ✓ Flagged as ATTACK:     {attacks_flagged_as_attack:4d} ({attack_detection_rate:.1%})\")\n",
        "    print(f\"  ⚠ Flagged as SUSPICIOUS: {attacks_flagged_as_suspicious:4d} ({suspicious_detection_rate:.1%})\")\n",
        "    print(f\"  ✗ Missed (flagged SAFE): {attacks_flagged_as_safe:4d} ({missed_attack_rate:.1%}) ← CRITICAL\")\n",
        "\n",
        "    print(f\"\\nNORMAL LOGS ({total_normal} total):\")\n",
        "    print(f\"  ✗ False ATTACK flags:    {normal_flagged_as_attack:4d} ({false_attack_rate:.1%}) ← BAD\")\n",
        "    print(f\"  ⚠ SUSPICIOUS flags:      {normal_flagged_as_suspicious:4d} ({normal_suspicious_rate:.1%}) ← OK\")\n",
        "    print(f\"  ✓ Correctly SAFE:        {normal_flagged_as_safe:4d} ({correct_safe_rate:.1%})\")\n",
        "\n",
        "    print(f\"\\nKEY PERFORMANCE INDICATORS:\")\n",
        "    print(f\"  🎯 Attack Detection (ATTACK+SUSPICIOUS): {(attack_detection_rate + suspicious_detection_rate):.1%}\")\n",
        "    print(f\"  🚨 Critical Misses (attacks as SAFE):    {missed_attack_rate:.1%}\")\n",
        "    print(f\"  ❌ False Attack Rate:                     {false_attack_rate:.1%}\")\n",
        "    print(f\"  📊 Efficiency (correct classifications):  {(attacks_flagged_as_attack + normal_flagged_as_safe)/(total_attacks + total_normal):.1%}\")\n",
        "\n",
        "    # Return key metrics\n",
        "    return {\n",
        "        'attack_detection_rate': attack_detection_rate + suspicious_detection_rate,\n",
        "        'critical_miss_rate': missed_attack_rate,\n",
        "        'false_attack_rate': false_attack_rate,\n",
        "        'efficiency': (attacks_flagged_as_attack + normal_flagged_as_safe)/(total_attacks + total_normal),\n",
        "        'missed_attacks': attacks_flagged_as_safe,\n",
        "        'false_attacks': normal_flagged_as_attack\n",
        "    }\n",
        "\n",
        "# Load and process all datasets\n",
        "print(\"Loading and processing datasets...\")\n",
        "X_train, y_train = load_data_and_extract_features(train)\n",
        "X_validate, y_validate = load_data_and_extract_features(validate)\n",
        "X_test, y_test = load_data_and_extract_features(test)\n",
        "\n",
        "print(f\"Training set: {len(X_train)} samples ({sum(y_train)} attacks)\")\n",
        "print(f\"Validation set: {len(X_validate)} samples ({sum(y_validate)} attacks)\")\n",
        "print(f\"Test set: {len(X_test)} samples ({sum(y_test)} attacks)\")\n",
        "\n",
        "# Create optimized model\n",
        "print(\"\\nTraining optimized model...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Use more conservative contamination and more trees\n",
        "iso_forest = IsolationForest(\n",
        "    n_estimators=1500,\n",
        "    max_samples=0.8,\n",
        "    contamination=0.02,  # Very low contamination\n",
        "    max_features=0.9,\n",
        "    bootstrap=True,\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "iso_forest.fit(X_train_scaled)\n",
        "\n",
        "# Get anomaly scores\n",
        "print(\"Computing anomaly scores...\")\n",
        "X_validate_scaled = scaler.transform(X_validate)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "val_scores = iso_forest.decision_function(X_validate_scaled)\n",
        "test_scores = iso_forest.decision_function(X_test_scaled)\n",
        "\n",
        "# Combine for threshold finding\n",
        "combined_scores = np.concatenate([val_scores, test_scores])\n",
        "combined_labels = np.array(y_validate + y_test)\n",
        "\n",
        "# Find optimal thresholds\n",
        "print(\"Finding optimal three-tier thresholds...\")\n",
        "attack_threshold, safe_threshold = find_three_tier_thresholds(combined_labels, combined_scores)\n",
        "\n",
        "print(f\"Attack threshold: {attack_threshold:.4f}\")\n",
        "print(f\"Safe threshold: {safe_threshold:.4f}\")\n",
        "\n",
        "# Classify all samples\n",
        "combined_classifications = classify_three_tier(combined_scores, attack_threshold, safe_threshold)\n",
        "\n",
        "# Evaluate\n",
        "metrics = evaluate_three_tier(combined_labels, combined_classifications)\n",
        "\n",
        "print(f\"\\nFEATURE IMPORTANCE INSIGHTS:\")\n",
        "feature_names = X_train.columns.tolist()\n",
        "print(\"Top features to monitor:\")\n",
        "for i, name in enumerate(feature_names[:10]):\n",
        "    print(f\"  {i+1:2d}. {name}\")\n",
        "\n",
        "print(f\"\\nRECOMMENDATIONS:\")\n",
        "if metrics['critical_miss_rate'] > 0.02:\n",
        "    print(f\"⚠️  Consider lowering attack threshold to: {attack_threshold * 1.1:.4f}\")\n",
        "if metrics['false_attack_rate'] > 0.1:\n",
        "    print(f\"⚠️  Consider raising attack threshold to: {attack_threshold * 0.9:.4f}\")\n",
        "\n",
        "print(f\"\\nThreshold Configuration:\")\n",
        "print(f\"  attack_threshold = {attack_threshold:.6f}\")\n",
        "print(f\"  safe_threshold = {safe_threshold:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ntbntUx3oS",
        "outputId": "15921d7d-d86b-4370-9029-005faaa8b4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and processing datasets...\n",
            "Training set: 833 samples (0 attacks)\n",
            "Validation set: 4372 samples (0 attacks)\n",
            "Test set: 746 samples (746 attacks)\n",
            "\n",
            "Training optimized model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done 1500 out of 1500 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing anomaly scores...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=1)]: Done 1500 out of 1500 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding optimal three-tier thresholds...\n",
            "Score range: -0.172 to 0.226\n",
            "Attack threshold: -0.0017\n",
            "Safe threshold: 0.1803\n",
            "======================================================================\n",
            "THREE-TIER CLASSIFICATION RESULTS\n",
            "======================================================================\n",
            "ATTACK LOGS (746 total):\n",
            "  ✓ Flagged as ATTACK:      197 (26.4%)\n",
            "  ⚠ Flagged as SUSPICIOUS:  506 (67.8%)\n",
            "  ✗ Missed (flagged SAFE):   43 (5.8%) ← CRITICAL\n",
            "\n",
            "NORMAL LOGS (4372 total):\n",
            "  ✗ False ATTACK flags:     316 (7.2%) ← BAD\n",
            "  ⚠ SUSPICIOUS flags:      3088 (70.6%) ← OK\n",
            "  ✓ Correctly SAFE:         968 (22.1%)\n",
            "\n",
            "KEY PERFORMANCE INDICATORS:\n",
            "  🎯 Attack Detection (ATTACK+SUSPICIOUS): 94.2%\n",
            "  🚨 Critical Misses (attacks as SAFE):    5.8%\n",
            "  ❌ False Attack Rate:                     7.2%\n",
            "  📊 Efficiency (correct classifications):  22.8%\n",
            "\n",
            "FEATURE IMPORTANCE INSIGHTS:\n",
            "Top features to monitor:\n",
            "   1. weighted_activity\n",
            "   2. priv_esc_intensity\n",
            "   3. system_mod_intensity\n",
            "   4. unknown_intensity\n",
            "   5. injection_intensity\n",
            "   6. red_flag_score\n",
            "   7. unique_syscalls\n",
            "   8. max_concentration\n",
            "   9. diversity_intensity_ratio\n",
            "  10. non_benign_ratio\n",
            "\n",
            "RECOMMENDATIONS:\n",
            "⚠️  Consider lowering attack threshold to: -0.0019\n",
            "\n",
            "Threshold Configuration:\n",
            "  attack_threshold = -0.001730\n",
            "  safe_threshold = 0.180334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done 1500 out of 1500 | elapsed:    0.3s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R3W5t_x8BWu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iaiSmX_Dpamc"
      }
    }
  ]
}